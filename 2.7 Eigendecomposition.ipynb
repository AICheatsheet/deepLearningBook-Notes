{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsp/.virtualenvs/kaggle/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Plot parameters\n",
    "sns.set()\n",
    "# Seven hls color palette\n",
    "current_palette_7 = sns.color_palette(\"hls\", 7)\n",
    "sns.set_palette(current_palette_7)\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['xtick.major.size'] = 0\n",
    "plt.rcParams['ytick.major.size'] = 0\n",
    "# rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Avoid inaccurate floating values (for inverse matrices in dot product for instance)\n",
    "# See https://stackoverflow.com/questions/24537791/numpy-matrix-inversion-rounding-errors\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 Eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvectors and eigenvalues\n",
    "\n",
    "- The number of eigenvalue/eigenvector corresponds to the number of dimension of our data.\n",
    "- The eigenvector tells us the direction and the eigenvalue the amount of variance when data is projected on the axis of the corresponding eigenvector.\n",
    "- The eigenvector of the maximum eigenvalue is the principal component (i.e axis where the variance is maximum when data is projetted on).\n",
    "\n",
    "Let's say that $\\boldsymbol{A}$ is a matrix. This matrix $\\boldsymbol{A}$ can *act* on a vector $\\boldsymbol{v}$ and output another vector $\\boldsymbol{Av}$. It will input the vector $\\boldsymbol{v}$ and output the vector $\\boldsymbol{Av}$.\n",
    "\n",
    "The eigenvectors of a matrix are the output vectors that are in the same direction than the input vectors. This means that $\\boldsymbol{v}$ is a eigenvector of $\\boldsymbol{A}$ if $\\boldsymbol{v}$ and $\\boldsymbol{Av}$ are in the same direction that is if the vectors $\\boldsymbol{Av}$ and $\\boldsymbol{v}$ are parallel. The output vector is just a scaled version of the input vector. This scalling factor is $\\lambda$ and is called the **eigenvalue** of $\\boldsymbol{A}$.\n",
    "\n",
    "$$\n",
    "\\boldsymbol{Av} = \\lambda\\boldsymbol{v}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 (from [1])\n",
    "\n",
    "Let's $\\boldsymbol{A}$ be the following matrix\n",
    "\n",
    "$\n",
    "\\boldsymbol{A}=\n",
    "\\begin{bmatrix}\n",
    "    5 & 1\\\\\\\\\n",
    "    3 & 3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "One eigenvector of A is\n",
    "\n",
    "$\n",
    "\\boldsymbol{v}=\n",
    "\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    1\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "We can check that $\\boldsymbol{Av} = \\lambda\\boldsymbol{v}$:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    5 & 1\\\\\\\\\n",
    "    3 & 3\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    1\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "    6\\\\\\\\\n",
    "    6\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "We can see that\n",
    "\n",
    "$\n",
    "6\\times \\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    1\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    6\\\\\\\\\n",
    "    6\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "which means that $\\boldsymbol{v}$ is well an eigenvector of $\\boldsymbol{A}$. Also, the corresponding eigenvalue is $\\lambda=6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent $\\boldsymbol{x}$ and $\\boldsymbol{Ax}$ to check that their directions are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[5 1]\n",
      " [3 3]]\n",
      "v:\n",
      "[[1]\n",
      " [1]]\n",
      "Av:\n",
      "[[6]\n",
      " [6]]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 7)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQIAAAECCAYAAAAVT9lQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADwBJREFUeJzt3X/s3HV9wPHnfb8tBUwFI6CwwtgyfSGZwgINiFh+DFYg\nSCCQmW1sUDSKmM2qYYEQSFyCIZG5LiFIooA/ggkyfoiw0EDGiDZZiUMyoO5VCM6sFVOoQmFQab/f\n2x93ha+13+9d7/Pj7j73fCQNPXJ3r/d90+/z+7nP3fferXa7jaTJNjXsBUgaPkMgyRBIMgSSMASS\nMASSgEWD3jAiLgEuBdrAfsAxwHszc1s5S5NUl1YZ7yOIiJuAn2TmrcWXJKluhZ8aRMTxwNFGQBpf\nZZwjuBr4Ugn3I2lICoUgIg4AIjMfK2k9koZg4JOFXSuAR/q5YrvdbrdarYLj+rNmzRoAVq9eXcs8\nacT1/MYrGoIAnu9rJa0WL774asFx/ZmdbTM1Vd88gIMPXlrbvDpnOa8Z83opFILMvLHI7SWNBt9Q\nJMkQSDIEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAEkjAE\nkii29+FVwHnAYuDmzLy9tFVJqtVARwQRcQrw4cw8CTgVOLzMRUmq16BHBCuBpyPiPmApcGV5S5JU\nt0FDcBBwBHAu8IfA/cBRZS1KUr0GPVm4FVibmTszcyOwPSIOKnFdkmo06BHBj4C/A/4pIg4D9qcT\nhwX1s/VSGaamWrXO26XOeU1+bE2e9+KL8OSTcOyx9T6+XgYKQWY+GBEfjYjH6WyweEVmtnvdzr0P\nx2+W88rx6quwbt00zzwzzRe/uKQ5ex9m5lWD3laaFG+8AevXT/PEE9Ps3Akf+tAMBx/cOTIYJUV3\nQ5a0Bzt2wBNPTLN+/TTbt3f+36JF8JGPzAx3YfPwnYVSBX75yxabN7feigDAccfNsHS0Tg28xRBI\nFTjssDbT029f3ndfOOGE0TwaAJ8aSKWbmYEHHlhE5hQRs8zMwLJls+y777BXNj9DIJVo9wice+5O\nNm9ucdhhPV9UGypDIJVkTxGYnoYjjhjtCIDnCKRSzBeBcWEIpILGPQJgCKRCmhABMATSwJoSATAE\n0kCaFAEwBNJea1oEwBBIe6WJEQBDIPWtqREAQyD1pckRAEMg9dT0CIAhkBY0CREAQyDNa1IiAIZA\n2qNJigAYAul3TFoEoOCvIUfEE8DL3Ys/y8xPFF+SNDyTGAEotgnqEqCdmaeXuB5paCY1AlDsiOAY\n4B0RsRaYBq7JzPXlLEuq1yRHAIqdI3gd+EpmrgQ+A9wREZ5z0NiZ9AhAsSOCjcBzAJn5bERsBQ4F\nNs93A7c8G89ZTZ43MwN33w2bNu3H8uVw4YXUEoG6v569FAnBZcAHgc929z9cCryw0A3c8mz8ZjV5\n3q4jgU2b9mPZsjdYsWInv/pV5WOH8vXspUgIbgVuj4gfArPAZZk5W+D+pNrMfTqwfDmsWDF5Twfm\nKrL34Q7g4hLXItVi93MCF15ILUcCo8yTe5oonhjcM0OgiWEE5mcINBGMwMIMgRrPCPRmCNRoRqA/\nhkCNZQT6ZwjUSEZg7xgCNY4R2HuGQI1iBAZjCNQYRmBwhkCNYASKMQQae0agOEOgsWYEymEINLaM\nQHkMgcaSESiXIdDYMQLlMwQaK0agGoZAY8MIVMcQaCwYgWoZAo08I1C9onsfHgL8GDgjMzeWsyTp\nbUagHgMfEUTEIuAWOjseSaUzAvUp8tTgRuBrwC9KWov0FiNQr4FCEBGXAlsy82GgVeqKNPGMQP0G\nPUewCpiNiDOBY4FvR8R5mblloRu59+F4zqpz3qTsRdiIvQ8z85Rdf4+IR4FP94oAuPfhOM6qc94k\n7UXYpL0Pd2mXcB+acO5FOFyFQ5CZp5exEE0u9yIcPt9QpKHyxOBoMAQaGiMwOgyBhsIIjBZDoNoZ\ngdFjCFQrIzCaDIFqYwRGlyFQLYzAaDMEqpwRGH2GQJUyAuPBEKgyRmB8GAJVwgiMF0Og0hmB8WMI\nVCojMJ4MgUpjBMaXIVApjMB4MwQqzAiMP0OgQoxAMxgCDcwINIch0ECMQLMYAu01I9A8A394aURM\nAV8HApgFLs/MDWUtTKPJCDRTkSOCjwHtzDwZuBb4cjlL0qgyAs01cAgy8/vAp7oXjwR+XcaCNJqM\nQLMV2tcgM2cj4pvA+cBFpaxII8cINF+r3S6+UVFEHAI8DnwgM9+Y52q17Yi0Zs0aAFavXl3XyMba\ntRfhhg1w9NH17UWoUvXcqLjIycKLgWWZeQOwHZjp/pmXex+O1yz3ImzOvF6KPDW4B7g9Ih7r3s/n\nMvPNAvenEeJehJNl4BBk5uvAx0tci0aEexFOHt9QpN/iicHJZAj0FiMwuQyBACMw6QyBjIAMwaQz\nAgJDMNGMgHYxBBPKCGguQzCBjIB2ZwgmjBHQnhiCCWIENB9DMCGMgBZiCCaAEVAvhqDhjID6YQga\nzAioX4agoYyA9oYhaCAjoL1lCBrGCGgQhqBBjIAGZQgawgioCEPQAEZARQ304aURsQi4jc4OR/sA\n12fmD0pcl/pkBFSGQY8ILgZeyswVwDnATeUtSf0yAirLoB9n/j3gru7fW8COcpajfhkBlWmgEHT3\nNCAiltIJwjVlLkoLMwIqW5Etzw6ns9vRTZl5Zz+36WfrpTJMTbVqnbdLHfN27UW4adN+LF9e316E\nTfxaTtK8XgY9WfgeYC3w2cx8tN/bufdhMe5F6LxB5/Uy6BHB1cCBwLURcR2dnY7PzszfDHh/6sG9\nCFWlQc8RrAbcc7wm7kWoqvmGohHniUHVwRCMMCOguhiCEWUEVCdDMIKMgOpmCEaMEdAwGIIRYgQ0\nLIZgRBgBDZMhGAFGQMNmCIbMCGgUGIIhMgIaFYZgSIyARokhGAIjoFFjCGpmBDSKDEGNjIBGlSGo\niRHQKDMENTACGnWGoGJGQOPAEFTICGhcGIKKGAGNE0NQASOgcVMoBBFxQkT0/XHmk8AIaBwV2eDk\nSuCvgdfKW854MwIaV0WOCJ4DLihrIePOCGicDRyCzLwX2FniWsbWrm3IjIDG1cBPDQbRxL0PZ2bg\n7jt3suGZHSxfvsS9CJ03kvN6KSMErX6v2LS9D2d2zPKvt7zAs49v408uOY4VK151L0LnjeS8XsoI\nQbuE+xgv7TZsfI61N2/muf/Zj/edsYwL/3zabcg0tgqFIDN/DpxU0lrGwtSm/2X63x/j/n87gNx6\nCPEH21l5+aGeE9BYq/UcwVjbsYN9HnqQ1jM/5b6Nf8x/bz2Eo969hbOvOAoW+74sjTdD0K/Fi3nj\ntJWsffgAcuv+HPXuLZx3+ivseN8fDXtlUmH+KOvTzJszPHTDBvLn+xO//zrnv/9pZk47FVp9nyuV\nRpZHBH2YeXOGh/7hSTY+tZP3f3ARK686kfaj25j9vWXDXppUCkPQw+4ROOu6Y5neZ5o3zzpn2EuT\nSuNTgwXMFwEAFi8e7uKkEhmCeSwYAalhDMEeGAFNGkOwGyOgSWQI5jACmlSGoMsIaJIZAoyANPEh\nMALShIfACEgdExsCIyC9bSJDYASk3zZxITAC0u+aqBAYAWnPJiYERkCa30SEwAhICyuy5VkLuBk4\nBtgOfDIzny9rYWUxAlJvRY4IzgeWZOZJwNXAV8tZUnmMgNSfIiE4GXgIIDPXA8eXsqISGQGpP0U+\nquydwCtzLu+MiKnMnN3TldesWcPsbD17obz22qu0Z9u8/K7/YP8/ha0H7sN37/xJpTOnplq1Pb46\nZzlv/Od94Quf73mdIiHYBszdS2neCLx1hakaP/G31WKfJS32f9eS2kbW+fhq/Vo6b+zn9VIkBOuA\nc4F/iYgTgacWuvLq1atr2+/tO9/5BlNTLf7i46uYWlTPCyN17mc3CXv1Oa9eRUJwL3BmRKzrXl5V\nwnpKVVcEpHE3cAgysw18psS1SBoSf2RKMgSSDIEkDIEkDIEkDIEkDIEkDIEkDIEkDIEkDIEkDIEk\nDIEkDIEkDIEkDIEkDIEkDIEkDIEkCoYgIi6IiDvKWoyk4Siy9+Ea4M+AJ8tbjqRhKHJEsA4/xVhq\nhJ5HBBFxGfB5oA20uv9dlZl3RcQpFa9PUg16hiAzbwNuq2Etkoak1W4Pvhlj94jg05n5l+UtSVLd\nfPlQUrEjAknN4BGBJEMgyRBIwhBIosBbjAcRERcAF2XmX1V0/y3gZuAYYDvwycx8vopZu809Abgh\nM0+reM4iOu/pOBLYB7g+M39Q4bwp4OtAALPA5Zm5oap5c+YeAvwYOCMzN1Y86wng5e7Fn2XmJyqe\ndxVwHrAYuDkzb69w1iXApXTeBLgfne+L92bmtt2vW9sRQfd3E66n8+7EqpwPLMnMk4Crga9WOAuA\niLiSzjfLkqpnARcDL2XmCuAc4KaK530MaGfmycC1wJcrnrcrdrcAr9cwawmdx3d690/VETgF+HD3\n3+epwOFVzsvMb2XmaZl5OvCfwN/uKQJQ71ODOn434WTgIYDMXA8cX/E8gOeAC2qYA/A9Ot+Q0Anq\njiqHZeb3gU91Lx4J/LrKeV03Al8DflHDrGOAd0TE2oh4pHtkV6WVwNMRcR9wP/BAxfMAiIjjgaMz\n89b5rlN6CCLisoh4KiL+a85/j8vMu8qetQfvBF6Zc3ln9/C2Mpl5L7CzyhlzZr2emf8XEUuBu4Br\napg5GxHfBP4ZqPRXziPiUmBLZj5MtUeOu7wOfCUzV9L5IXVHxf9eDgKOAy7qzvtuhbPmuhr40kJX\nKP0cwZB/N2EbsHTO5anMnB3SWioREYcD9wA3ZeaddczMzEu7z9sfj4gPZOYbFY1aBcxGxJnAscC3\nI+K8zNxS0byNdI7oyMxnI2IrcCiwuaJ5W4GfZuZOYGNEbI+IgzLzpYrmEREHAJGZjy10vaa9arCO\nznNnIuJE4KkaZ1f+Eywi3gOsBf4+M79Vw7yLuye3oHPydab7pxKZeUr3Oe1pdD7n4m8qjADAZcA/\nAkTEYXR+iLxQ4bwfAWfNmbc/nThUaQXwSK8r1fqqQQ3uBc6MiHXdy6tqnF3He7WvBg4Ero2I67oz\nz87M31Q07x7g9oh4jM6/lc9l5psVzdpdHV/PW+k8vh/SeVXksiqPIDPzwYj4aEQ8TucHxxWZWfXj\nDKDnK2f+roGkxj01kDQAQyDJEEgyBJIwBJIwBJIwBJIwBJKA/wfZVp0TjERaBgAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a8dffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.array([[5,1], [3, 3]])\n",
    "print 'A:\\n', A\n",
    "v = np.array([[1], [1]])\n",
    "print 'v:\\n', v\n",
    "Av = np.dot(A, v)\n",
    "print 'Av:\\n', Av\n",
    "\n",
    "plotVectors([v.flatten(), Av.flatten()], cols=['red', 'blue'])\n",
    "plt.ylim(-1, 7)\n",
    "plt.xlim(-1, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another eigenvector of $\\boldsymbol{A}$ is\n",
    "\n",
    "$\n",
    "\\boldsymbol{v}=\n",
    "\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "because\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    5 & 1\\\\\\\\\n",
    "    3 & 3\n",
    "\\end{bmatrix} \\times \\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    2\\\\\\\\\n",
    "    -6\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "and\n",
    "$\n",
    "2 \\times \\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    2\\\\\\\\\n",
    "    -6\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "So the corresponding eigenvalue is $\\lambda=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v:\n",
      "[[ 1]\n",
      " [-3]]\n",
      "Av:\n",
      "[[ 2]\n",
      " [-6]]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 3)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEfVJREFUeJzt3XuQXGWZx/FvzyQBAolcajKLsiIIeYhkQUAlsJkgXnCX\njQpKKSi3iLCyijWwRUl02atQUFLsQKGWXCKauCggWQhks1khQBJCgBQWoRYfEkG3QpEL1zAbIJfp\n/aN7tHc4M9PznnP6XPr3qaKS6Z7u532HmV/Oc/pMP5VqtYqIyFAdWS9ARPJJ4SAikRQOIhJJ4SAi\nkRQOIhJJ4SAikWKFg5kda2bLklqMiOTHuNAHmtmlwFlAf3LLEZG8iHPksB44NamFiEi+BIeDuy8E\ndia4FhHJEZ2QFJFIweccGlSa+aRqtVqtVJr61MLp6+sDoLe3N+OViEQK+sFLIhya+s2tSqXCli1v\nJFCuOV1dk1pWb2CgSkdH6/bXyr2pXjnqhYgVDu7+e+D4OM8hIvmkcw4iEknhICKRFA4iEknhICKR\nFA4iEknhICKRFA4iEknhICKRFA4iEknhICKRFA4iEknhICKRFA4iEknhICKRFA4iEknhICKRFA4i\nEknhICKRFA4iEknhICKR4ozDqwA/AI4E3gK+6u7PJbUwEclWnCOHU4Dd3P14YC5wbTJLEpE8iBMO\nM4ElAO6+GvhQIisSkVyIEw6TgdcbPt5pZjqHIVIScYbabAUaR+l0uPvAcJ/c19fHwEBTw7ES0dFR\naVm9/v7a9KL5829uSb1W7k31il/vkksuDnpcnHBYCcwG7jSzGcDa0R7Q0dHaWZmtrFetwvb+Hew+\neUJL6pX5a6l6+VCpVsMSrOHViiPqN81x92dHeEi1rPMIf/rTm9j26g7efvAYzviXg5kyvSvVeu0w\n21H1Eq3X2kG67l4FLgx9fJlUKhUmTh7H28DS65/njBv2pXNCZ9bLEolFJxAT0jmhk2NP2ostm6o8\nfstvsl6OSGwKhwR9+LzD6OqusHppP5uf3pL1ckRiUTgkqHNCJyd98yCg1l7s2r4r4xWJhFM4JGzK\n9C61F1IKCocUqL2QMlA4pEDthZSBwiElai+k6BQOKVJ7IUWmcEiR2gspMoVDytReSFEpHFpA7YUU\nkcKhBdReSBEpHFpE7YUUjcKhhdReSJEoHFpI7YUUicKhxdReSFEoHDKg9kKKQOGQAbUXUgQKh4yo\nvZC8UzhkSO2F5FmscDCzU83sZ0ktpt2ovZA8Cw4HM+sDrgDy/wb8Oab2QvIqzpHDSvTW9IlQeyF5\nNGo4mNlXzGytmT3V8Ocx7n5HKxbYDtReSB6NOtTG3ecB85Io1tU1afRPSlCr6g2ONotTr+vESXz8\nc6/z0D2v88wvnufES44a+fNL+rVUvfyIMytzzMo6cmxgoEpHRyV2vWlfPIhfL1/D/Xe9zJSjnht2\nrF4bjG9TvYTrhdBLmTmi9kLyJFY4uPtD7v6lpBYjevVC8kNHDjmkVy8kDxQOOaT2QvJA4ZBTai8k\nawqHHFN7IVlSOOSY2gvJksIh59ReSFYUDgWg9kKyoHAoALUXkgWFQ0E0thcP3/BU1suRNqBwKJDB\n9mL5va+rvZDUKRwKRO2FtJLCoWCmTO+iZ/a79OqFpE7hUECzvnGEXr2Q1CkcCkjthbSCwqGgdHGU\npE3hUGC6OErSpHAoMLUXkiaFQ8GpvZC0KBxKQO2FpEHhUAJqLyQNQW9Nb2aTgQXAZGA88Lfu/miS\nC5OxqbUXm1m1pJ/Hb/kNMy48POslScGFHjlcAvzK3T8KzAG+n9iKJJjaC0lSaDhcC/yo/vfxwJvJ\nLEfiUHshSRq1rTCzrwAXA1VqE7WrwBx3X2NmfwLMB76Z6iqlaWovJCmVarUa9EAz+zPg36idb1ja\nxEPCChVAX18fAL29vRmvpGbX9l3ceM5Ktmwa4Pxrp7H/B7uzXpJkqxLyoNATkh8Abge+4O5rm31c\nWecRJjUrs1nN7G3WBQdw2+XP8fN/epozbtiNzgmdqdZLkuolXy9E6DmHK4HdgOvMbJmZLQx8HkmJ\nLo6SuIKOHNz9lKQXIsn78HmHsf7JNaxe2s/BPVuGndotEkUXQZWYXr2QOBQOJaf2QkIpHNqALo6S\nEAqHNqD2QkIoHNqE2gsZK4VDG1F7IWOhcGgjai9kLBQObUbthTRL4dCG1F5IMxQObUjthTRD4dCm\n1F7IaBQObUzthYxE4dDG1F7ISBQObU7thQxH4SBqLySSwkHUXkgkhYMAw7QXAwPZLkoypXCQPxja\nXox/8H7YpaOIdqVwkD9obC/+61/X0fHYE3S8sCHjVUlWFA7yR/39vGerc/zUzWx+qZMVGw6ic/2z\nWa9KMhL61vQTqc2s2Bd4CzjH3V9McmGSgb32ojpxIjP3W8mze07kkQ3vY+qTzt5fKO3IERlB6JHD\n+cAT7j4L+BnwreSWJFna+cGj2XH66cw+/DkA7l1zALs26uXNdhQUDu5+HXBF/cP3Aq8mtiLJ3MB7\nD2Tvv/k8x33gVTb/7148fPvGrJckGYg7K/N+YDrwyVRXKS1X3Wdfjvm7j+GXOcsf2EHXxyt0d6u9\naCfBszIHmZkB97n7IaN8amm/s/I2KzNJL74wwE3ffp6uo97DBRftTmf4VD3JTktnZV4GbHD3BcA2\nYGczjyvrPMI8zspMyrgJ0HPu+1l831vcc882Zs5M/7qHdphdWeZZmfOAL5vZMmABMCfweaQAZs2C\nrinw6KOdbNoU9I+QFFDorMzNwF8mvBbJqc5OOPnkncyfP57Fi8dx9tk71F60AV0EJU3p7q4yY8Yu\ntmypsGqVkqEdKBykaccdt4uurqraizahcJCmDbYXAIsXj9PvZJWcwkHGRO1F+1A4yJipvWgPCgcZ\nM7UX7UHhIEHUXpSfwkGCqb0oN4WDBFN7UW4KB4lF7UV5KRwkNrUX5aRwkNjUXpSTwkESofaifBQO\nkhi1F+WicJDEqL0oF4WDJErtRXkoHCRxai/KQeEgiVN7UQ4KB0mF2oviUzhIatReFFuscDCzw8zs\nNTObkNSCpDzUXhRbcDiY2STgGmqDdEUiqb0orjhHDjcCc6kNtREZltqLYhrrrMxB/wPc5u5rzUz/\nt2VEmntRTEGzMs3sWWADtRl8M4DV7v7RUR6mWZltbtkyeOghOOEEOPHErFfTVlo3K9Pdpw7+3cye\np8kp22WdR1jmWZlJ1ps2DR5/fDxLllTo6tox7NTuou4vz/VCJPFSZpXAZJL2olcviiV2OLj7we6+\nPYnFSPnp1Yvi0EVQ0nJ69aIYFA7ScmovikHhIJlQe5F/CgfJjNqLfFM4SGbUXuSbwkEypfYivxQO\nkjm1F/mkcJDMqb3IJ4WD5EJje/Hww1mvRkDhIDky2F4sX47aixxQOEhuqL3IF4WD5Ep3d5WeHvTq\nRQ4oHCR3Zs1Cr17kgMJBckftRT4oHCSXdHFU9hQOklu6OCpbCgfJLbUX2VI4SK6pvciOwkFyT+1F\nNhQOkntqL7IR9Nb0AGa2AXi2/uEqd/9OMksSeafB9uKRRzpZtaqTmTOVEGkLCgczez+wxt0/m/B6\nRIZ13HG7WLeug0cf7eTQQweGnXshyQhtK44BDjCzB8zsXjObOuojRGJSe9FaY52VWan/+XXgSnf/\npZn9ObAA+EiaCxUBtRetNGo4uPs8YF7jbWa2B7Czfv9KM3t3M8VCx3KFalW9jo5KS+u1ulbe6n3m\nM7BxI6xdCzNmwP77p1svDa2uFyL0hOQ/AC8D3zOzI6lN3R5VWecRalZm6+v19FSYP3888+dXY0/t\nzuP+kq4XIvScw1XACWb2IHANcG7g84gE0cVR6Qudsv0aMDvhtYiMiV69SJcugpLC0qsX6VI4SKGp\nvUiPwkEKT797kQ6FgxSe2ot0KBykFNReJE/hIKWh9iJZCgcpDbUXyVI4SKmovUiOwkFKR+1FMhQO\nUjpqL5KhcJBSUnsRn8JBSkvtRTwKBykttRfxKByk1NRehFM4SOmpvQijcJDSU3sRRuEgbSGqvejv\nz3hROadwkLbR2F787ncV7r57fNZLyjWFg7SNxvbizjvH88ILFV55JeNF5ZjCQdrGpk0VliypvW3q\nwEDttvXr9SMwnNBxeB3AtdQmX+0G/KO7L05yYSJJ6+6u0tOzk0WLxvP227XbfvtbhcNwQr8yZwHj\n3L0HOAU4JLkliaTn4IOrnHnmDvbZp/ZO1Rs2dLBtW8aLyqnQcPgU8IKZ3QvcCCxKbkki6dpvv1pA\nHHjgANUqrFuX9YryaayzMgdtAd5099lmNgu4FTghlRWKpGCPPeC003aybFkn7vDupgY6tpdKtTr2\nQSBmdhtwu7svrH/8oruPNrGwtBNH+vr6AOjt7c14JRLiqadg+nToKO/ph6DLQkNnZa4ATgYW1mdl\n/r6ZB5V1HqFmZRa73hFHlHt/obMyQ8PhJuCHZraq/vHXAp9HRHIqdFbmduC8hNciIjlS3i5LRGJR\nOIhIJIWDiERSOIhIJIWDiERSOIhIJIWDiERSOIhIJIWDiERSOIhIJIWDiERSOIhIJIWDiERSOIhI\nJIWDiERSOIhIJIWDiERSOIhIJIWDiEQKHYf3LeAvqL3d/D5At7vrnf9FSiT0DWavBq4GMLNFwKVJ\nLkpEsherrTCzzwGvuPuvElqPiOTEWMfhVep/znH3NcBlwOmprlBEMjFqOLj7PGDe0NvNbBrwqrs/\nl8bCRCRbQbMyAczsIqDT3fuSXZKI5EGccw5TAR01iJRU8JGDiJSbLoISkUgKBxGJpHAQkUgKBxGJ\nFHT5dLPM7FTgNHf/csR95wMXADuAK9z9vhh1dgcWAFOArcA57v7ykM+5G9i3Xu9Nd/+rgDoV4AfA\nkcBbwFcbr/NIck9N1rsOOB54o37TZ939jXc80dhqHgtc5e4nDrn908Dl1Pb2Y3e/OU6dJupdDJwH\nbK7f9Nfuvi5GnXHUrtd5HzCB2v+fRQ33J7q/Juolvb8O4CbAgAHga+7+3w33j3l/qYWDmfUBJwG/\njrivG7gIOBqYCKwws6XuviOw3IXAU+7+z2b2RWpfhN4hn3OIux8e+PyDTgF2c/fj69/U19ZvS2NP\nI9arOxr4lLu/EqPGH5jZpcBZQP+Q28fVax8DvAmsNLN73H3zO58lfr26o4Gz3P3JODUanAm85O5n\nm9m+wJPAovo60tjfsPXqkt7fp4Gqu880sxOAK/nj92bQ/tJsK1ZS+6GN8hFghbvvdPetwDrgiBi1\nZgJL6n//D+ATjXea2RRgbzO7x8weNrMxHzUMrePuq4EPNdyX9J5GrFc/qjgUuNHMVpjZnJi1ANYD\np0bcPg1Y5+5b62G3AuhJsR7UvpHnmtlyM7ssgVq3U/tHA2q/BtAY2mnsb6R6kPD+3P1uaketUDta\nebXh7qD9xT5yGOF3L+6oJ1iUycDrDR/3A+8KqEe95saG53uj/vyNJgDXANcB+1FLztXu/lIzNUdY\n904z63D3gYj7mt5TYL09geup/YswDlhmZo+7+9Ohxdx9oZkd2MQ63iD+3kaqB3Ab8H1qbeK/m9nJ\n7r44Rq1tAGY2CbgD+E7D3Ynvb5R6kPD+6jUHzOxWakcMpzXcFbS/2OEw3O9ejGIr//8HeBLwWmg9\nM/tl/TmGe66NwI/qP1RbzOxJar3ZWMNha0MdgMEf1MH7gvYUWG8bcL27vwVgZg9QOzcRHA6jrCPp\nvY3muvoRGGZ2H3AUEOuHx8z+FLgLuMHdf9FwVyr7G6EepLA/AHc/t36k/JiZTXP3NwncX6onJEfw\nGPBdM5sA7AEcRrxv6pXAycAT9T+XD7n/E8A3gNlmthdwOPBMYJ3ZwJ1mNgNY23Bf0nsard5U4Odm\ndhS1/48zgVtj1htUGfLxM8AhZrY3tVCaBXwvoVrvqGdmk4Gnzewwaj3yx4Bb4hSonxP6T+Dr7r5s\nyN2J72+keint70zgAHe/itrJ6131/yBwfy0Nh/oZ2nXufq+ZXU+t96kA33b37TGe+ofAT8xsOfA2\n8KV6vauBO9x9iZmdZGarqH3B5gaexFsIfNLMVtY/npPinpqptwBYDWwHfuLuIYEXpQpgZmcAe7r7\nzWZ2CbCU2t5udvcXE6o1XL25wIPUvtHvd/clIzy+GXOBvYHLzezv6zVvIr39jVYv6f3dBfzYzB6i\n9nPdC3zezIL3p9+tEJFIughKRCIpHEQkksJBRCIpHEQkksJBRCIpHEQkksJBRCIpHEQk0v8BCL2i\nbgyLposAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109b24e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = np.array([[1], [-3]])\n",
    "print 'v:\\n', v\n",
    "Av = np.dot(A, v)\n",
    "print 'Av:\\n', Av\n",
    "\n",
    "plotVectors([v.flatten(), Av.flatten()], cols=['red', 'blue'])\n",
    "plt.ylim(-7, 1)\n",
    "plt.xlim(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows that the eigenvector $\\boldsymbol{v}$ is a vector that changes only in scale when we apply it to the matrix $\\boldsymbol{A}$. Here the scales were 6 for the first eigenvector and 2 to the second but $\\lambda$ can take any real or even complex value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find eigenvalues and eigenvectors in Python\n",
    "\n",
    "Numpy provides a function returning eigenvectors and eigenvalues (the first array corresponds to the eigenvalues and the second to the eigenvectors concatenated in columns):\n",
    "\n",
    "```python\n",
    "(array([ 6.,  2.]), array([[ 0.70710678, -0.31622777],\n",
    "       [ 0.70710678,  0.9486833 ]]))\n",
    "```\n",
    "\n",
    "Here a demonstration with the preceding example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[5 1]\n",
      " [3 3]]\n",
      "\n",
      "Eigenvalues and eigenvectors from np.linalg.eig(A):\n",
      "(array([ 6.,  2.]), array([[ 0.70710678, -0.31622777],\n",
      "       [ 0.70710678,  0.9486833 ]]))\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[5, 1], [3, 3]])\n",
    "print 'A:\\n', A\n",
    "print '\\nEigenvalues and eigenvectors from np.linalg.eig(A):\\n', np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the eigenvalues are the same than the ones we used before: 6 and 2 (first array).\n",
    "\n",
    "The eigenvectors correspond to the columns of the second array. This means that the eigenvector corresponding to $\\lambda=6$ is $\\begin{bmatrix}\n",
    "    0.70710678\\\\\\\\\n",
    "    0.70710678\n",
    "\\end{bmatrix}$ and the eigenvector corresponding to $\\lambda=2$ is $\\begin{bmatrix}\n",
    "    -0.31622777\\\\\\\\\n",
    "    0.9486833\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "The eigenvectors look different because they have not necessarly the same scaling than the ones we gave in the example. We can easily see that the first corresponds to a scaled version of our $\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    1\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "For the second we need to check that it corresponds to a scaled version of $\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix}$ so let's draw these vectors and see if they are parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v:\n",
      "[[ 1]\n",
      " [-3]]\n",
      "Av:\n",
      "[[ 2]\n",
      " [-6]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1, 3)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAECCAYAAADzZhIUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkMJBRAIpHEQkkMJBRAIpHEQk0P8BImIebVHM7VsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109b24410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = np.array([[1], [-3]])\n",
    "print 'v:\\n', v\n",
    "Av = np.dot(A, v)\n",
    "print 'Av:\\n', Av\n",
    "v_np = [-0.31622777, 0.9486833]\n",
    "\n",
    "plotVectors([v.flatten(), Av.flatten(), v_np], cols=['red', 'blue', 'green'])\n",
    "plt.ylim(-7, 1)\n",
    "plt.xlim(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the vector found with numpy (in green) is well a scaled version of our preceding $\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaled vectors\n",
    "\n",
    "As we saw it with numpy, if $\\boldsymbol{v}$ is an eigenvector of $\\boldsymbol{A}$, then any rescaled vector $s\\boldsymbol{v}$ is also an eigenvector of $\\boldsymbol{A}$. The eigenvalue of the rescaled vector is the same.\n",
    "\n",
    "Let's try to rescale $\n",
    "\\boldsymbol{v}=\n",
    "\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix}\n",
    "$ from our preceding example. \n",
    "\n",
    "For instance,\n",
    "\n",
    "$\n",
    "\\boldsymbol{3v}=\n",
    "\\begin{bmatrix}\n",
    "    3\\\\\\\\\n",
    "    -9\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    5 & 1\\\\\\\\\n",
    "    3 & 3\n",
    "\\end{bmatrix} \\times\n",
    "\\begin{bmatrix}\n",
    "    3\\\\\\\\\n",
    "    -9\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    6\\\\\\\\\n",
    "    18\n",
    "\\end{bmatrix} = 2 \\times\n",
    "\\begin{bmatrix}\n",
    "    3\\\\\\\\\n",
    "    -9\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "We have well $\\boldsymbol{A\\times 3v} = \\lambda\\boldsymbol{v}$ and the eigenvalue is still $\\lambda=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating eigenvalues and eigenvectors\n",
    "\n",
    "All eigenvectors of a matrix $\\boldsymbol{A}$ can be concatenated in a matrix with each column corresponding to each eigenvector (like in the second array return by `np.linalg.eig(A)`):\n",
    "\n",
    "$\n",
    "\\boldsymbol{V}=\n",
    "\\begin{bmatrix}\n",
    "    1 & 1\\\\\\\\\n",
    "    1 & -3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The first column $\n",
    "\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    1\n",
    "\\end{bmatrix}\n",
    "$ corresponds to $\\lambda=6$ and the second $\n",
    "\\begin{bmatrix}\n",
    "    1\\\\\\\\\n",
    "    -3\n",
    "\\end{bmatrix}\n",
    "$ to $\\lambda=2$.\n",
    "\n",
    "The vector $\\boldsymbol{\\lambda}$ can be created from all eigenvalues:\n",
    "\n",
    "$\\boldsymbol{\\lambda}=\n",
    "\\begin{bmatrix}\n",
    "    6\\\\\\\\\n",
    "    2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Then the eigendecomposition is given by\n",
    "\n",
    "$\n",
    "\\boldsymbol{A}=\\boldsymbol{V}\\cdot diag(\\boldsymbol{\\lambda}) \\cdot \\boldsymbol{V}^{-1}\n",
    "$\n",
    "\n",
    "Continuing with our example we have\n",
    "\n",
    "$\n",
    "\\boldsymbol{V}=\\begin{bmatrix}\n",
    "    1 & 1\\\\\\\\\n",
    "    1 & -3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The diagonal matrix is all zeros except the diagonal that is our vector $\\boldsymbol{\\lambda}$.\n",
    "\n",
    "$\n",
    "diag(\\boldsymbol{v})=\n",
    "\\begin{bmatrix}\n",
    "    6 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The inverse matrix of $\\boldsymbol{V}$ can be calculated with numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:\n",
      "[[ 1  1]\n",
      " [ 1 -3]]\n",
      "V_inv:\n",
      "[[ 0.75  0.25]\n",
      " [ 0.25 -0.25]]\n"
     ]
    }
   ],
   "source": [
    "V = np.array([[1, 1], [1, -3]])\n",
    "print 'V:\\n', V\n",
    "V_inv = np.linalg.inv(V)\n",
    "print 'V_inv:\\n', V_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So\n",
    "\n",
    "$\n",
    "\\boldsymbol{V}^{-1}=\\begin{bmatrix}\n",
    "    0.75 & 0.25\\\\\\\\\n",
    "    0.25 & -0.25\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "and our equation becomes\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    1 & 1\\\\\\\\\n",
    "    1 & -3\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    6 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    0.75 & 0.25\\\\\\\\\n",
    "    0.25 & -0.25\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    1 & 1\\\\\\\\\n",
    "    1 & -3\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    6 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    6 & -6\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    6 & -6\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    0.75 & 0.25\\\\\\\\\n",
    "    0.25 & -0.25\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    6\\times0.75 + (2\\times0.25) & 6\\times0.25 + (2\\times-0.25)\\\\\\\\\n",
    "    6\\times0.75 + (-6\\times0.25) & 6\\times0.25 + (-6\\times-0.25)\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    5 & 1\\\\\\\\\n",
    "    3 & 3\n",
    "\\end{bmatrix} =\n",
    "\\boldsymbol{A}\n",
    "$\n",
    "\n",
    "Let's check our result with Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of lambdas:\n",
      "[[6 0]\n",
      " [0 2]]\n",
      "V.dot(lambdas).dot(V_inv):\n",
      "[[ 5.  1.]\n",
      " [ 3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.diag([6,2])\n",
    "print 'Vector of lambdas:\\n', lambdas\n",
    "print 'V.dot(lambdas).dot(V_inv):\\n', V.dot(lambdas).dot(V_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's confirm our previous calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real symmetric matrix\n",
    "\n",
    "In the case of real symmetric matrices, the eigendecomposition can be expressed as\n",
    "\n",
    "$\n",
    "\\boldsymbol{A} = \\boldsymbol{Q}\\Lambda \\boldsymbol{Q}^\\text{T}\n",
    "$\n",
    "\n",
    "where $\\boldsymbol{Q}$ is the matrix with eigenvalues as columns and $\\Lambda$ is $diag(\\lambda)$.\n",
    "\n",
    "### Example 2.\n",
    "\n",
    "$\n",
    "\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    2 & 3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "This matrix is symmetric because $\\boldsymbol{A}=\\boldsymbol{A}^\\text{T}$. Its eigenvectors are\n",
    "\n",
    "$\n",
    "\\boldsymbol{Q}=\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 & -0.4472136\\\\\\\\\n",
    "    0.4472136 & 0.89442719\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "and its eigenvalues put in a diagonal matrix gives\n",
    "\n",
    "$\n",
    "\\boldsymbol{\\Lambda}=\n",
    "\\begin{bmatrix}\n",
    "    7 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "So let's begin to calculate $\\boldsymbol{Q\\Lambda}$:\n",
    "\n",
    "$\n",
    "\\boldsymbol{A} = \\boldsymbol{Q\\Lambda}=\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 & -0.4472136\\\\\\\\\n",
    "    0.4472136 & 0.89442719\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    7 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 \\times 7 + -0.4472136\\times 0 & 0.89442719 \\times 0 + -0.4472136\\times 2\\\\\\\\\n",
    "    0.4472136 \\times 7 + 0.89442719\\times 0 & 0.4472136 \\times 0 + 0.89442719\\times 2\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    6.26099033 & -0.8944272\\\\\\\\\n",
    "    3.1304952 & 1.78885438\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "with\n",
    "\n",
    "$\n",
    "\\boldsymbol{Q}^\\text{T}=\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 & 0.4472136\\\\\\\\\n",
    "    -0.4472136 & 0.89442719\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "So we have\n",
    "\n",
    "$\n",
    "\\boldsymbol{A} = \\boldsymbol{Q\\Lambda} \\boldsymbol{Q}^\\text{T}=\n",
    "\\begin{bmatrix}\n",
    "    6.26099033 & -0.8944272\\\\\\\\\n",
    "    3.1304952 & 1.78885438\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 & 0.4472136\\\\\\\\\n",
    "    -0.4472136 & 0.89442719\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    2 & 3\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Let's do the same things easily with `linalg` from numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[6 2]\n",
      " [2 3]]\n",
      "\n",
      "Eigenvalues of A:\n",
      "[[ 7.  0.]\n",
      " [ 0.  2.]]\n",
      "\n",
      "Eigenvectors of A:\n",
      "[[ 0.89442719 -0.4472136 ]\n",
      " [ 0.4472136   0.89442719]]\n",
      "\n",
      "eigVecs.dot(eigVals).dot(eigVecs.T):\n",
      "[[ 6.  2.]\n",
      " [ 2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[6, 2], [2, 3]])\n",
    "print 'A:\\n', A\n",
    "eigVals = np.diag(np.linalg.eig(A)[0])\n",
    "print '\\nEigenvalues of A:\\n', eigVals\n",
    "eigVecs = np.linalg.eig(A)[1]\n",
    "print '\\nEigenvectors of A:\\n', eigVecs\n",
    "\n",
    "print '\\neigVecs.dot(eigVals).dot(eigVecs.T):\\n', eigVecs.dot(eigVals).dot(eigVecs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the result corresponds to our initial matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A matrix is singular if any eigenvalue is equal to 0.\n",
    "\n",
    "# Quadratic to matrix form\n",
    "\n",
    "More details [7].\n",
    "\n",
    "\n",
    "Let's have the following quadratic equation:\n",
    "\n",
    "$f(\\boldsymbol{x}) = ax_1^2 +(b+c)x_1x_2 + dx_2^2$\n",
    "\n",
    "These quadratic forms can be generated by matrices:\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x})= \\begin{bmatrix}\n",
    "    x_1 & x_2\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    a & b\\\\\\\\\n",
    "    c & d\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix} = \\boldsymbol{x^\\text{T}Ax}\n",
    "$\n",
    "\n",
    "with $\\boldsymbol{x} = \\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix}$ and $\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    a & b\\\\\\\\\n",
    "    c & d\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "We call them matrix forms. This form is useful to do various things on the quadratic equation like constrained optimization (see bellow).\n",
    "\n",
    "If you look at the relation between these forms you can see that $a$ gives you the number of $x_1^2$, $(b + c)$ the number of $x_1x_2$ and $d$ the number of $x_2^2$. This means that the same quadratic form can be obtained from infinite number of matrices $\\boldsymbol{A}$ by changing $b$ and $c$ while preserving their sum.\n",
    "\n",
    "### Example 3.\n",
    "\n",
    "$\\boldsymbol{x} = \\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix}$ and $\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    2 & 4\\\\\\\\\n",
    "    2 & 5\n",
    "\\end{bmatrix}$\n",
    "\n",
    "gives the following quadratic form:\n",
    "\n",
    "$2x_1^2 + (4+2)x_1x_2 + 5x_2^2\\\\\\\\=2x_1^2 + 6x_1x_2 + 5x_2^2$\n",
    "\n",
    "but if $\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    2 & -3\\\\\\\\\n",
    "    9 & 5\n",
    "\\end{bmatrix}$ we still have the quadratic same form:\n",
    "\n",
    "$2x_1^2 + (-3+9)x_1x_2 + 5x_2^2\\\\\\\\=2x_1^2 + 6x_1x_2 + 5x_2^2$\n",
    "\n",
    "The implication is that every quadratic form can be obtained from a symmetric matrix. For this example $\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    2 & 3\\\\\\\\\n",
    "    3 & 5\n",
    "\\end{bmatrix}$ gives us the same quadratic form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "For this example, we will go from the matrix form to the quadratic form using a symmetric matrix $\\boldsymbol{A}$.\n",
    "\n",
    "$\\boldsymbol{x} = \\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix}$ and $\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    2 & 3\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\boldsymbol{x^\\text{T}Ax}&=\n",
    "\\begin{bmatrix}\n",
    "    x_1 & x_2\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    2 & 3\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix}\\\\\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    x_1 & x_2\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    6 x_1 + 2 x_2\\\\\\\\\n",
    "    2 x_1 + 3 x_2\n",
    "\\end{bmatrix}\\\\\\\\\n",
    "&=\n",
    "x_1(6 x_1 + 2 x_2) + x_2(2 x_1 + 3 x_2)\\\\\\\\\n",
    "&=\n",
    "6 x_1^2 + 4 x_1x_2 + 3 x_2^2\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Our quadratic equation is thus $6 x_1^2 + 4 x_1x_2 + 3 x_2^2$.\n",
    "\n",
    "### Note\n",
    "\n",
    "If $\\boldsymbol{A}$ is a diagonal matrix (all 0 except the diagonal), the quadratic form of $\\boldsymbol{x^\\text{T}Ax}$ will have no cross term. Take the following matrix form:\n",
    "\n",
    "$\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    a & b\\\\\\\\\n",
    "    c & d\n",
    "\\end{bmatrix}$\n",
    "\n",
    "If $\\boldsymbol{A}$ is diagonal, then $b$ and $c$ are 0 and since $f(\\boldsymbol{x}) = ax_1^2 +(b+c)x_1x_2 + dx_2^2$ there is no cross term.\n",
    "\n",
    "\n",
    "A quadratic form without cross term is called diagonal form since it comes from a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change of variable - quadratic form\n",
    "\n",
    "A change of variable (or linear substitution) simply means that we replace a variable by another one. We will see that it can be used to remove the cross terms in our quadratic equation. Without the cross term, it will then be easier to characterize the function and eventually optimize it (i.e finding its maximum or minimum).\n",
    "\n",
    "### Example 5.\n",
    "\n",
    "Let's take again our previous quadratic form:\n",
    "\n",
    "$\n",
    "\\boldsymbol{x^\\text{T}Ax} = 6 x_1^2 + 4 x_1x_2 + 3 x_2^2\n",
    "$\n",
    "\n",
    "The change of variable will concern $x_1$ and $x_2$. We can replace $x_1$ with any combination of $y_1$ and $y_2$ and $x_2$ also with any combination $y_1$ and $y_2$. We will of course end up with a new equation. The nice thing is that we can find a specific substitution that will lead to a simplification of our statement. Specifically, it can be used to get rid of the cross term (in example 5. $4 x_1x_2$). We will see later why it is interesting.\n",
    "\n",
    "Actually, the right substitution is given by the eigenvectors of the matrix used to generate the quadratic form. Let's recall that the quadratic form came from:\n",
    "\n",
    "$\\boldsymbol{x} = \\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix}$ and $\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    6 & 2\\\\\\\\\n",
    "    2 & 3\n",
    "\\end{bmatrix}$\n",
    "\n",
    "and that the eigenvectors were:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 & -0.4472136\\\\\\\\\n",
    "    0.4472136 & 0.89442719\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "With the purpose of simplification, we can replace these values with:\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    \\frac{2}{\\sqrt{5}} & -\\frac{1}{\\sqrt{5}}\\\\\\\\\n",
    "    \\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}}\n",
    "\\end{bmatrix} =\n",
    "\\frac{1}{\\sqrt{5}}\n",
    "\\begin{bmatrix}\n",
    "    2 & -1\\\\\\\\\n",
    "    1 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "So our first eigenvector is $\n",
    "\\frac{1}{\\sqrt{5}}\n",
    "\\begin{bmatrix}\n",
    "    2\\\\\\\\\n",
    "    1\n",
    "\\end{bmatrix}\n",
    "$ and our second eigenvector is $\n",
    "\\frac{1}{\\sqrt{5}}\n",
    "\\begin{bmatrix}\n",
    "    -1\\\\\\\\\n",
    "    2\n",
    "\\end{bmatrix}\n",
    "$.\n",
    "\n",
    "The change of variable will lead to\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "    x_1\\\\\\\\\n",
    "    x_2\n",
    "\\end{bmatrix} =\n",
    "\\frac{1}{\\sqrt{5}}\n",
    "\\begin{bmatrix}\n",
    "    2 & -1\\\\\\\\\n",
    "    1 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    y_1\\\\\\\\\n",
    "    y_2\n",
    "\\end{bmatrix} =\n",
    "\\frac{1}{\\sqrt{5}}\n",
    "\\begin{bmatrix}\n",
    "    2y_1 - y_2\\\\\\\\\n",
    "    y_1 + 2y_2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "so we have\n",
    "\n",
    "$\n",
    "\\begin{cases}\n",
    "x_1 = \\frac{1}{\\sqrt{5}}(2y_1 - y_2)\\\\\\\\\n",
    "x_2 = \\frac{1}{\\sqrt{5}}(y_1 + 2y_2)\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "\n",
    "So far so good! Let's replace that in our example:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\boldsymbol{x^\\text{T}Ax}\n",
    "&=\n",
    "6 x_1^2 + 4 x_1x_2 + 3 x_2^2\\\\\\\\\n",
    "&=\n",
    "6 [\\frac{1}{\\sqrt{5}}(2y_1 - y_2)]^2 + 4 [\\frac{1}{\\sqrt{5}}(2y_1 - y_2)\\frac{1}{\\sqrt{5}}(y_1 + 2y_2)] + 3 [\\frac{1}{\\sqrt{5}}(y_1 + 2y_2)]^2\\\\\\\\\n",
    "&=\n",
    "\\frac{1}{5}[6 (2y_1 - y_2)^2 + 4 (2y_1 - y_2)(y_1 + 2y_2) + 3 (y_1 + 2y_2)^2]\\\\\\\\\n",
    "&=\n",
    "\\frac{1}{5}[6 (4y_1^2 - 4y_1y_2 + y_2^2) + 4 (2y_1^2 + 4y_1y_2 - y_1y_2 - 2y_2^2) + 3 (y_1^2 + 4y_1y_2 + 4y_2^2)]\\\\\\\\\n",
    "&=\n",
    "\\frac{1}{5}(24y_1^2 - 24y_1y_2 + 6y_2^2 + 8y_1^2 + 16y_1y_2 - 4y_1y_2 - 8y_2^2 + 3y_1^2 + 12y_1y_2 + 12y_2^2)\\\\\\\\\n",
    "&=\n",
    "\\frac{1}{5}(35y_1^2 + 10y_2^2)\\\\\\\\\n",
    "&=\n",
    "7y_1^2 + 2y_2^2\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "That's great! Our new equation doesn't have cross terms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change of variable - Principal Axes Theorem\n",
    "\n",
    "[7] slide 10.\n",
    "\n",
    "Actually there is a simpler way to do the change of variable. We can stay in the matrix form. Recall that we start with the form:\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x})=\\boldsymbol{x^\\text{T}Ax}\n",
    "$\n",
    "\n",
    "The linear substitution can be wrote in these terms. We want replace the variables $\\boldsymbol{x}$ by $\\boldsymbol{y}$ that relates by:\n",
    "\n",
    "$\n",
    "\\boldsymbol{x}=P\\boldsymbol{y}\n",
    "$\n",
    "\n",
    "We want to find $P$ such as our new equation (after the change of variable) doesn't contain the cross terms.\n",
    "\n",
    "The first step is to replace that in the first equation:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\boldsymbol{x^\\text{T}Ax}\n",
    "&=\n",
    "(\\boldsymbol{Py})^\\text{T}\\boldsymbol{A}(\\boldsymbol{Py})\\\\\\\\\n",
    "&=\n",
    "\\boldsymbol{y}^\\text{T}(\\boldsymbol{P}^\\text{T}\\boldsymbol{AP})\\boldsymbol{y}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "We can see that the substitution is done by replacing $\\boldsymbol{A}$ with $\\boldsymbol{P^\\text{T}AP}$. Remember from example 2. that $\\boldsymbol{A} = \\boldsymbol{Q\\Lambda} \\boldsymbol{Q}^\\text{T}$ ($\\boldsymbol{\\Lambda}$ is the eigenvalues of $\\boldsymbol{A}$ put in a diagonal matrix):\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\boldsymbol{P^\\text{T}AP}\n",
    "&=\n",
    "\\boldsymbol{P^\\text{T}Q\\Lambda Q^\\text{T}P}\\\\\\\\\n",
    "&=\n",
    "\\boldsymbol{P^\\text{T}PQQ^\\text{T}\\Lambda}\\\\\\\\\n",
    "&=\n",
    "\\boldsymbol{\\Lambda}\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "Since $\\boldsymbol{P}$ and $\\boldsymbol{Q}$ are orthogonal we can remove $\\boldsymbol{P^\\text{T}P}$ and $\\boldsymbol{QQ^\\text{T}}$. We finally have:\n",
    "\n",
    "$\n",
    "\\boldsymbol{x^\\text{T}Ax}=\\boldsymbol{y^\\text{T}\\Lambda y}\n",
    "$\n",
    "\n",
    "All of this implies that we can use $\\boldsymbol{\\Lambda}$ to simplify our quadratic equation and remove the cross terms. If you remember from example 2 we know that the eigenvalues of $\\boldsymbol{A}$ are:\n",
    "\n",
    "$\n",
    "\\boldsymbol{\\Lambda}=\n",
    "\\begin{bmatrix}\n",
    "    7 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "\\boldsymbol{x^\\text{T}Ax}\n",
    "&=\n",
    "\\boldsymbol{y^\\text{T}\\Lambda y}\\\\\\\\\n",
    "&=\n",
    "\\boldsymbol{y}^\\text{T}\\cdot\\begin{bmatrix}\n",
    "    7 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix}\\cdot\\boldsymbol{y}\\\\\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    y_1 & y_2\n",
    "\\end{bmatrix}\\cdot\\begin{bmatrix}\n",
    "    7 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix}\\cdot\\begin{bmatrix}\n",
    "    y_1\\\\\\\\\n",
    "    y_2\n",
    "\\end{bmatrix}\\\\\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    7y_1 +0y_2 & 0y_1 + 2y_2\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "    y_1\\\\\\\\\n",
    "    y_2\n",
    "\\end{bmatrix}\\\\\\\\\n",
    "&=\n",
    "7y_1^2 + 2y_2^2\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "That's nice! If you look back to the change of variable that we have done in the quadratic form, you will see that we have found the same values!\n",
    "\n",
    "This form (without cross-term) is called the **principal axes form**.\n",
    "\n",
    "### Summary\n",
    "\n",
    "To summarise, the principal axes form can be found with\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x^\\text{T}Ax} = \\lambda_1y_1^2 + \\lambda_2y_2^2\n",
    "$$\n",
    "\n",
    "where $\\lambda_1$ is the eigenvalue corresponding to the first eigenvector (first column of $\\boldsymbol{x}$) and $\\lambda_2$ the eigenvalue corresponding to the second eigenvector (second column of $\\boldsymbol{x}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding f(x) with eigendecomposition\n",
    "\n",
    "We will see that there is a way to find $f(\\boldsymbol{x})$ with eigenvectors and eigenvalues when $\\boldsymbol{x}$ is a unit vector. \n",
    "\n",
    "Let's start from\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x}) =\\boldsymbol{x^\\text{T}Ax}\n",
    "$.\n",
    "\n",
    "We know that if $\\boldsymbol{x}$ is an eigenvector of $\\boldsymbol{A}$ and $\\lambda$ the corresponding eigenvalue, then $\n",
    "\\boldsymbol{Ax}=\\lambda \\boldsymbol{x}\n",
    "$. By replacing the term in the last equation we have\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x}) =\\boldsymbol{x^\\text{T}\\lambda x} = \\boldsymbol{x^\\text{T}x}\\lambda\n",
    "$\n",
    "\n",
    "Since $\\boldsymbol{x}$ is a unit vector, $|\\boldsymbol{x}|_2=1$ and $\\boldsymbol{x^\\text{T}x}=1$ (cf. 2.5 Norms). We end up with\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x}) = \\lambda\n",
    "$\n",
    "\n",
    "This is a usefull property. If $\\boldsymbol{x}$ is an eigenvector of $\\boldsymbol{A}$, $\n",
    "f(\\boldsymbol{x}) =\\boldsymbol{x^\\text{T}Ax}$ will take the value of the corresponding eigenvalue [5]. We can see that this is working only if the euclidean norm of $\\boldsymbol{x}$ is 1 (i.e $\\boldsymbol{x}$ is a unit vector).\n",
    "\n",
    "### Example 6\n",
    "\n",
    "This example will show that $f(\\boldsymbol{x}) = \\lambda$. Let's take again the last example, the eigenvectors of $\\boldsymbol{A}$ were\n",
    "\n",
    "$\n",
    "\\boldsymbol{Q}=\n",
    "\\begin{bmatrix}\n",
    "    0.89442719 & -0.4472136\\\\\\\\\n",
    "    0.4472136 & 0.89442719\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "and the eigenvalues\n",
    "\n",
    "$\n",
    "\\boldsymbol{\\Lambda}=\n",
    "\\begin{bmatrix}\n",
    "    7 & 0\\\\\\\\\n",
    "    0 & 2\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "So if $\\boldsymbol{x}=\\begin{bmatrix}\n",
    "    0.89442719 & 0.4472136\n",
    "\\end{bmatrix}$, $f(\\boldsymbol{x})$ should be equal to 7. Let's check that's true.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "f(\\boldsymbol{x}) &= 6 x_1^2 + 4 x_1x_2 + 3 x_2^2\\\\\\\\\n",
    "&= 6\\times 0.89442719^2 + 4\\times 0.89442719\\times 0.4472136 + 3 \\times 0.4472136^2\\\\\\\\\n",
    "&= 7\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "In the same way, if $\\boldsymbol{x}=\\begin{bmatrix}\n",
    "    -0.4472136 & 0.89442719\n",
    "\\end{bmatrix}$, $f(\\boldsymbol{x})$ should be equal to 2.\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "f(\\boldsymbol{x}) &= 6 x_1^2 + 4 x_1x_2 + 3 x_2^2\\\\\\\\\n",
    "&= 6\\times -0.4472136^2 + 4\\times -0.4472136\\times 0.89442719 + 3 \\times 0.89442719^2\\\\\\\\\n",
    "&= 2\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic form optimization\n",
    "\n",
    "Depending to the context, optimizing a function means finding its maximum or its minimum. It is for instance widely used to minimize the error of cost functions in machine learning.\n",
    "\n",
    "Here we will see how eigendecomposition can be used to optimize quadratic functions and why this can be done easily without cross terms. The difficulty is that we want a constrained optimization, that is to find the minimum or the maximum of the function for $f(x)$ being a unit vector.\n",
    "\n",
    "### Example 7.\n",
    "\n",
    "See [6] slide 36.\n",
    "\n",
    "We want to optimize:\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x}) =\\boldsymbol{x^\\text{T}Ax}\n",
    "$\n",
    "\n",
    "subject to $||\\boldsymbol{x}||_2= 1$.\n",
    "\n",
    "In our last example we ended up with:\n",
    "\n",
    "$\n",
    "f(\\boldsymbol{x}) = 7y_1^2 + 2y_2^2\n",
    "$\n",
    "\n",
    "And the constraint of $\\boldsymbol{x}$ being a unit vector imply:\n",
    "\n",
    "$\n",
    "||\\boldsymbol{x}||_2 = 1 \\Leftrightarrow x_1^2 + x_2^2 = 1\n",
    "$\n",
    "\n",
    "We can also show that $\\boldsymbol{y}$ has to be a unit vector if it is the case for $\\boldsymbol{x}$. Recall first that $\\boldsymbol{x}=\\boldsymbol{Py}$:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "||\\boldsymbol{x}||^2 &= \\boldsymbol{x^\\text{T}x}\\\\\\\\\n",
    "&= (\\boldsymbol{Py})^\\text{T}(\\boldsymbol{Py})\\\\\\\\\n",
    "&= \\boldsymbol{P^\\text{T}y^\\text{T}Py}\\\\\\\\\n",
    "&= \\boldsymbol{PP^\\text{T}y^\\text{T}y}\\\\\\\\\n",
    "&= \\boldsymbol{y^\\text{T}y} = ||\\boldsymbol{y}||^2\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "So $||\\boldsymbol{x}||^2 = ||\\boldsymbol{y}||^2 = 1$ and thus $y_1^2 + y_2^2 = 1$\n",
    "\n",
    "Since $y_1^2$ and $y_2^2$ cannot be negative because they are squared values, we can be sure that $2y_2^2\\leq7y_2^2$. Hence:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "f(\\boldsymbol{x}) &= 7y_1^2 + 2y_2^2\\\\\\\\\n",
    "&\\leq\n",
    "7y_1^2 + 7y_2^2\\\\\\\\\n",
    "&=\n",
    "7(y_1^2+y_2^2)\\\\\\\\\n",
    "&=\n",
    "7\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "This means that the maximum value of $f(\\boldsymbol{x})$ is 7.\n",
    "\n",
    "The same way can lead to find the minimum of $f(\\boldsymbol{x})$. $7y_1^2\\geq2y_1^2$ and:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "f(\\boldsymbol{x}) &= 7y_1^2 + 2y_2^2\\\\\\\\\n",
    "&\\geq\n",
    "2y_1^2 + 2y_2^2\\\\\\\\\n",
    "&=\n",
    "2(y_1^2+y_2^2)\\\\\\\\\n",
    "&=\n",
    "2\n",
    "\\end{align*}\n",
    "$\n",
    "\n",
    "And the minimum of $f(\\boldsymbol{x})$ is 2.\n",
    "\n",
    "### Summary\n",
    "\n",
    "We can note that the minimum of $f(\\boldsymbol{x})$ is the minimum eigenvalue of the corresponding matrix $\\boldsymbol{A}$. Another useful fact is that this value is obtained when $\\boldsymbol{x}$ takes the value of the corresponding eigenvector (check back the preceding paragraph). In that way, $f(\\boldsymbol{x})=7$ when $\\boldsymbol{x}=[0.89442719, 0.4472136]$. Let's check that in replacing in the orginal quadratic equation:\n",
    "\n",
    "This shows how useful are the eigenvalues and eigenvector in this kind of constrained optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical views\n",
    "\n",
    "We saw that the quadratic functions $f(\\boldsymbol{x}) = ax_1^2 +2bx_1x_2 + cx_2^2$ can be represented by the symmetric matrix $\\boldsymbol{A}$:\n",
    "\n",
    "$\\boldsymbol{A}=\\begin{bmatrix}\n",
    "    a & b\\\\\\\\\n",
    "    b & c\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Graphically, these functions can take one of three general shape (click on the links to go to the Surface Plotter and move the shapes):\n",
    "\n",
    "1. [Positive-definite form](https://academo.org/demos/3d-surface-plotter/?expression=x*x%2By*y&xRange=-50%2C+50&yRange=-50%2C+50&resolution=49) | 2. [Negative-definite form](https://academo.org/demos/3d-surface-plotter/?expression=-x*x-y*y&xRange=-50%2C+50&yRange=-50%2C+50&resolution=25) | 3. [Indefinite form](https://academo.org/demos/3d-surface-plotter/?expression=x*x-y*y&xRange=-50%2C+50&yRange=-50%2C+50&resolution=49)\n",
    ":-------------------------:|:-------------------------:|:-------:\n",
    "![positiveDefiniteForm.png](images/positiveDefiniteForm.png) | ![negativeDefiniteForm.png](images/negativeDefiniteForm.png) | ![IndefiniteForm.png](images/IndefiniteForm.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "With the constraints that $\\boldsymbol{x}$ is a unit vector, the minimum of the function $f(\\boldsymbol{x})$ corresponds to the smallest eigenvalue and is obtained with its corresponding eigenvector. The maximum corresponds to the biggest eigenvalue and is obtained with its corresponding eigenvector.\n",
    "\n",
    "The corresponding quadratic expression of $\n",
    "f(\\boldsymbol{x}) = \\boldsymbol{x^\\text{T}Ax}\n",
    "$ we want to optimize is $\\boldsymbol{x}_1^2+\\boldsymbol{x}_1\\boldsymbol{x}_2+\\boldsymbol{x}_2^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reference\n",
    "\n",
    "[1] [Gilbert Strang, Lec21 MIT - Eigenvalues and eigenvectors](https://www.youtube.com/watch?v=lXNXrLcoerU)\n",
    "\n",
    "[2] [Gilbert Strang, Lec 21 MIT, Spring 2005](https://www.youtube.com/watch?v=lXNXrLcoerU)\n",
    "\n",
    "[3] [Principal Component Analysis 4 Dummies](https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/)\n",
    "\n",
    "[4] [Eric Sullivan from University of Colorado, Denver](http://math.ucdenver.edu/~esulliva/LinearAlgebra/SlideShows/07_02.pdf)\n",
    "\n",
    "[5] [math.stackexchange QA](https://math.stackexchange.com/questions/2207111/eigendecomposition-optimization-of-quadratic-expressions)\n",
    "\n",
    "[6] [C.O.S. Sorzano from Universidad San Pablo](http://biocomp.cnb.csic.es/~coss/Docencia/algebra/tema8.pdf)\n",
    "\n",
    "[7] [Quadratic forms (C. R. Platt from University of Manitoba)](https://home.cc.umanitoba.ca/~platt/M2300/L23-quadforms-p6.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARcAAAECCAYAAADUyJP8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1098c5510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotVectors(vecs, cols):\n",
    "    plt.figure()\n",
    "    print len(vecs)\n",
    "    for i in range(len(vecs)):\n",
    "        x = np.concatenate([[0,0],vecs[i]])\n",
    "#     y = np.concatenate([[0,0],vecs[1]])\n",
    "    \n",
    "\n",
    "        plt.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles='xy', scale_units='xy', scale=1, color=cols[i],\n",
    "                  alpha=1/float((len(vecs))))\n",
    "\n",
    "#     plt.xlim(-1, 2)\n",
    "#     plt.ylim(-1, 2)\n",
    "    plt.axvline(x=0, color='grey')\n",
    "    plt.axhline(y=0, color='grey')\n",
    "\n",
    "#     plt.text(1, 1.5, r'$\\vec{u}$', size=18)\n",
    "#     plt.text(1.5, -1, r'$\\vec{v}$', size=18)\n",
    "\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "x = [0,1]\n",
    "y = [1,0]\n",
    "plotVectors([x,y], cols=['red', 'blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89442719  0.4472136 ]\n",
      " [-0.4472136   0.89442719]]\n",
      "[[ 0.89442719  0.4472136 ]\n",
      " [-0.4472136   0.89442719]]\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print np.linalg.eig(test)[1].T\n",
    "print np.linalg.inv(np.linalg.eig(test)[1])\n",
    "print np.linalg.eig(test)[1].T.dot(np.linalg.eig(test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
