# Reading notes on the Deep Learning book (Notes on the Deep Learning book : Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning. MIT press.)

![screenshot1](screenshot1.png)

I'd like to introduce a series of Python Notebook gathering notes on the Deep Learning book from Goodfellow, I., Bengio, Y., and Courville, A. (2016). The notes actually cover the chapter 2 on Linear Algebra. I like this introduction to linear algebra because it gives a sense of what is most use in the domain of machine learning and deep learning. It is thus a great syllabus for anyone who want to get the minimum knowledge of linear algebra needed to experiment with deep learning algorithms or to better understand them.

You can find all the notebooks on [my Github]().

# Getting started with linear algebra

The idea of this series is to provide details aimed at beginners who wants to understand enough linear algebra to be confortable with deep learning. Indeed, I think that the linear algebra ressource proposed in the Deep Learning book is a bit scarce for beginner. In my journey I found a lot of great people exposing their understanding through blogs, university websites etc (see the thanks section!). I tried to develop each part with the help these ressources in order to add a lot of steps that may not be obvious for beginners.

# The use of Python/Numpy

In addition, I always need to find and create examples to understand theory. I choose to build Python notebook instead or just gather mathematical explanations. The goal is two folds:

1. Provide a starting point to use Python/Numpy to apply linear algebra concepts. And since the final aim is to use linear algebra concepts for deep learning it seems natural to continuously go between theory and code.

2. Give a more concrete vision of the underlying concepts.

# Syllabus

The syllabus follow exactly the Deep Learning book so you can find more details if you can't understand one specific point while you are reading it.

1. [Scalars, Vectors, Matrices and Tensors]()
2. [Multiplying Matrices and Vectors]()
3. [Identity and Inverse Matrices]()
4. [Linear Dependence and Span]()
5. [Norms]()
6. [Special Kinds of Matrices and Vectors]()
7. [Eigendecomposition]()
8. Singular Value Decomposition
9. The Moore-Penrose Pseudoinverse
10. The Trace Operator
11. The Determinant
12. Example: Principal Components Analysis

